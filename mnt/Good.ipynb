{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6022a83f-a98a-49d7-b9b5-6be56e9a74d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abstract: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- n_citation: long (nullable = true)\n",
      " |-- references: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- venue: string (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "|            abstract|             authors|                  id|n_citation|          references|               title|               venue|year|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "|Based on biologic...|[Guoping Pang, La...|4aa69add-3978-480...|         8|[04754a28-6bf4-4d...|Dynamic analysis ...|Mathematics and C...|2008|\n",
      "|In this paper, a ...|[S. Ben Jabra, Ez...|4ab3735c-80f1-472...|        50|[09cb2d7d-47d1-4a...|A new approach of...|international sym...|2008|\n",
      "|The purpose of th...|[Makoto Satoh, Ry...|00127ee2-cb05-48c...|         0|[51c7e02e-f5ed-43...|Preliminary Desig...|international con...|2013|\n",
      "|AdaBoost algorith...|[Zheng Xu, Runbin...|001eef4f-1d00-4ae...|         0|[0a11984c-ab6e-4b...|A Heterogeneous S...|high performance ...|2016|\n",
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+--------------------+----+\n",
      "\n",
      "Number of records: 4\n",
      "+-------+--------------------+--------------------+-----------------+--------------------+--------------------+------------------+\n",
      "|summary|            abstract|                  id|       n_citation|               title|               venue|              year|\n",
      "+-------+--------------------+--------------------+-----------------+--------------------+--------------------+------------------+\n",
      "|  count|                   4|                   4|                4|                   4|                   4|                 4|\n",
      "|   mean|                NULL|                NULL|             14.5|                NULL|                NULL|           2011.25|\n",
      "| stddev|                NULL|                NULL|23.96525262402492|                NULL|                NULL|3.9475730941089733|\n",
      "|    min|AdaBoost algorith...|00127ee2-cb05-48c...|                0|A Heterogeneous S...|Mathematics and C...|              2008|\n",
      "|    max|The purpose of th...|4ab3735c-80f1-472...|               50|Preliminary Desig...|international sym...|              2016|\n",
      "+-------+--------------------+--------------------+-----------------+--------------------+--------------------+------------------+\n",
      "\n",
      "+--------+-------+---+----------+----------+-----+-----+----+\n",
      "|abstract|authors| id|n_citation|references|title|venue|year|\n",
      "+--------+-------+---+----------+----------+-----+-----+----+\n",
      "|       0|      0|  0|         0|         0|    0|    0|   0|\n",
      "+--------+-------+---+----------+----------+-----+-----+----+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|       n_citation|\n",
      "+-------+-----------------+\n",
      "|  count|                4|\n",
      "|   mean|             14.5|\n",
      "| stddev|23.96525262402492|\n",
      "|    min|                0|\n",
      "|    max|               50|\n",
      "+-------+-----------------+\n",
      "\n",
      "+--------+-------+---+----------+----------+-----+-----+----+\n",
      "|abstract|authors| id|n_citation|references|title|venue|year|\n",
      "+--------+-------+---+----------+----------+-----+-----+----+\n",
      "+--------+-------+---+----------+----------+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark_session = SparkSession.builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config('spark.yarn.appMasterEnv.ARROW_PRE_0_15_IPC_FORMAT', '1') \\\n",
    "    .config('spark.executorEnv.ARROW_PRE_0_15_IPC_FORMAT', '1') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark = spark_session\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = spark.read.json(\"./dblp-ref/*.json\", multiLine=True)\n",
    "\n",
    "# Show the schema to understand the structure\n",
    "df.printSchema()\n",
    "\n",
    "# Display a sample of the data\n",
    "df.show(5)\n",
    "\n",
    "# Count the number of records\n",
    "print(f\"Number of records: {df.count()}\")\n",
    "\n",
    "# Display summary statisticss\n",
    "df.describe().show()\n",
    "\n",
    "# Check for missing values (excluding `isnan`)\n",
    "df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "\n",
    "# Distribution of citations\n",
    "df.select(\"n_citation\").describe().show()\n",
    "\n",
    "# Check for null abstracts and titles\n",
    "df.filter(df.abstract.isNull() | df.title.isNull()).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63314b8a-e761-4bac-bb42-a64483ed12e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langid in /opt/conda/lib/python3.11/site-packages (1.1.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from langid) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0b4a4b3-556b-4a13-ab35-261452a9c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langid\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Function to detect language using langid\n",
    "def detect_language(text):\n",
    "    if text is None:\n",
    "        return None\n",
    "    lang, _ = langid.classify(text)\n",
    "    return lang\n",
    "\n",
    "# Registering UDF\n",
    "lang_detect_udf = udf(detect_language, StringType())\n",
    "\n",
    "# Add a new column for language detection\n",
    "df = df.withColumn(\"language\", lang_detect_udf(df.abstract))\n",
    "\n",
    "# Filter only English documents\n",
    "df = df.filter(df.language == 'en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1263a8f-5e28-4d88-b950-75bdac5948fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |cleaned_abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |tokenized_abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |filtered_abstract                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|Based on biological control strategy in pest management, we construct and investigate a pest-epidemic model with impulsive control, i.e., periodic spraying microbial pesticide and releasing infected pests at different fixed moments. By using Floquet theorem and comparison theorem, we prove that the pest-eradication periodic solution is globally asymptotically stable when the impulsive period @t is less than the critical value @t\"m\"a\"x\"@?. Otherwise, the system can be permanent. Moreover, numerical results clearly show with the increase of the impulsive period @t, the system exhibits a wide variety of dynamic behaviors including a sequence of direct and inverse cascade of periodic-doubling, symmetry-breaking pitchfork bifurcation, chaos and non-unique dynamics, which implies that the impulsive effect makes the dynamic behavior of the system more complex.                                                                                                                                                                                                                                                                                                                                |based on biological control strategy in pest management we construct and investigate a pestepidemic model with impulsive control ie periodic spraying microbial pesticide and releasing infected pests at different fixed moments by using floquet theorem and comparison theorem we prove that the pesteradication periodic solution is globally asymptotically stable when the impulsive period t is less than the critical value tmax otherwise the system can be permanent moreover numerical results clearly show with the increase of the impulsive period t the system exhibits a wide variety of dynamic behaviors including a sequence of direct and inverse cascade of periodicdoubling symmetrybreaking pitchfork bifurcation chaos and nonunique dynamics which implies that the impulsive effect makes the dynamic behavior of the system more complex                                                                                                                                                                                                                                                                                                                                  |[based, on, biological, control, strategy, in, pest, management, we, construct, and, investigate, a, pestepidemic, model, with, impulsive, control, ie, periodic, spraying, microbial, pesticide, and, releasing, infected, pests, at, different, fixed, moments, by, using, floquet, theorem, and, comparison, theorem, we, prove, that, the, pesteradication, periodic, solution, is, globally, asymptotically, stable, when, the, impulsive, period, t, is, less, than, the, critical, value, tmax, otherwise, the, system, can, be, permanent, moreover, numerical, results, clearly, show, with, the, increase, of, the, impulsive, period, t, the, system, exhibits, a, wide, variety, of, dynamic, behaviors, including, a, sequence, of, direct, and, inverse, cascade, of, periodicdoubling, symmetrybreaking, pitchfork, bifurcation, chaos, and, nonunique, dynamics, which, implies, that, the, impulsive, effect, makes, the, dynamic, behavior, of, the, system, more, complex]                                                                                                                                                                                                                                                                                                                                                                           |[based, biological, control, strategy, pest, management, construct, investigate, pestepidemic, model, impulsive, control, ie, periodic, spraying, microbial, pesticide, releasing, infected, pests, different, fixed, moments, floquet, theorem, comparison, theorem, prove, pesteradication, periodic, solution, globally, asymptotically, stable, impulsive, period, less, critical, value, tmax, otherwise, system, permanent, moreover, numerical, results, clearly, show, increase, impulsive, period, system, exhibits, wide, variety, dynamic, behaviors, including, sequence, direct, inverse, cascade, periodicdoubling, symmetrybreaking, pitchfork, bifurcation, chaos, nonunique, dynamics, implies, impulsive, effect, makes, dynamic, behavior, system, complex]                                                                                                                                                                                                                                                                                                                             |\n",
      "|In this paper, a robust 3D triangular mesh watermarking algorithm based on 3D segmentation is proposed. In this algorithm three classes of watermarking are combined. First, we segment the original image to many different regions. Then we mark every type of region with the corresponding algorithm based on their curvature value. The experiments show that our watermarking is robust against numerous attacks including RST transformations, smoothing, additive random noise, cropping, simplification and remeshing.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |in this paper a robust 3d triangular mesh watermarking algorithm based on 3d segmentation is proposed in this algorithm three classes of watermarking are combined first we segment the original image to many different regions then we mark every type of region with the corresponding algorithm based on their curvature value the experiments show that our watermarking is robust against numerous attacks including rst transformations smoothing additive random noise cropping simplification and remeshing                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |[in, this, paper, a, robust, 3d, triangular, mesh, watermarking, algorithm, based, on, 3d, segmentation, is, proposed, in, this, algorithm, three, classes, of, watermarking, are, combined, first, we, segment, the, original, image, to, many, different, regions, then, we, mark, every, type, of, region, with, the, corresponding, algorithm, based, on, their, curvature, value, the, experiments, show, that, our, watermarking, is, robust, against, numerous, attacks, including, rst, transformations, smoothing, additive, random, noise, cropping, simplification, and, remeshing]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |[paper, robust, 3d, triangular, mesh, watermarking, algorithm, based, 3d, segmentation, proposed, algorithm, three, classes, watermarking, combined, first, segment, original, image, many, different, regions, mark, every, type, region, corresponding, algorithm, based, curvature, value, experiments, show, watermarking, robust, numerous, attacks, including, rst, transformations, smoothing, additive, random, noise, cropping, simplification, remeshing]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|The purpose of this study is to develop a learning tool for high school students studying the scientific aspects of information and communication net- works. More specifically, we focus on the basic principles of network proto- cols as the aim to develop our learning tool. Our tool gives students hands-on experience to help understand the basic principles of network protocols.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |the purpose of this study is to develop a learning tool for high school students studying the scientific aspects of information and communication net works more specifically we focus on the basic principles of network proto cols as the aim to develop our learning tool our tool gives students handson experience to help understand the basic principles of network protocols                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |[the, purpose, of, this, study, is, to, develop, a, learning, tool, for, high, school, students, studying, the, scientific, aspects, of, information, and, communication, net, works, more, specifically, we, focus, on, the, basic, principles, of, network, proto, cols, as, the, aim, to, develop, our, learning, tool, our, tool, gives, students, handson, experience, to, help, understand, the, basic, principles, of, network, protocols]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |[purpose, study, develop, learning, tool, high, school, students, studying, scientific, aspects, information, communication, net, works, specifically, focus, basic, principles, network, proto, cols, aim, develop, learning, tool, tool, gives, students, handson, experience, help, understand, basic, principles, network, protocols]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|AdaBoost algorithm based on Haar-like features can achieves high accuracy (above 95%) in object detection. Meanwhile massive computing power is needed to implement the cascaded classifiers involved in AdaBoost detection. To solve this problem, several dedicated hardware solutions have been proposed for real-time applications. In this work, a novel heterogeneous architecture of an AdaBoost detector is presented. This architecture achieves higher performance while consuming fewer hardware resources. By combining an integrated ARM Cortex-A9 processor with a dedicated accelerator, this architecture can be configured to realize various objects detection by simply loading different parameters. 2-D parallelism is involved in accelerator unit combination which brings more flexibility. This scheme is implemented on Xilinx ZC702 platform, the experiment result shows that 40 QVGA frames per second can be achieved for real-time face detection. The accelerator achieves more than 13 times improvement over the OpenCV implementation on a standalone Cortex-A9 w.r.t execution speed. Meanwhile, the accelerator consumes 40% less FPGA hardware resources than the prior-art implementation.|adaboost algorithm based on haarlike features can achieves high accuracy above 95 in object detection meanwhile massive computing power is needed to implement the cascaded classifiers involved in adaboost detection to solve this problem several dedicated hardware solutions have been proposed for realtime applications in this work a novel heterogeneous architecture of an adaboost detector is presented this architecture achieves higher performance while consuming fewer hardware resources by combining an integrated arm cortexa9 processor with a dedicated accelerator this architecture can be configured to realize various objects detection by simply loading different parameters 2d parallelism is involved in accelerator unit combination which brings more flexibility this scheme is implemented on xilinx zc702 platform the experiment result shows that 40 qvga frames per second can be achieved for realtime face detection the accelerator achieves more than 13 times improvement over the opencv implementation on a standalone cortexa9 wrt execution speed meanwhile the accelerator consumes 40 less fpga hardware resources than the priorart implementation|[adaboost, algorithm, based, on, haarlike, features, can, achieves, high, accuracy, above, 95, in, object, detection, meanwhile, massive, computing, power, is, needed, to, implement, the, cascaded, classifiers, involved, in, adaboost, detection, to, solve, this, problem, several, dedicated, hardware, solutions, have, been, proposed, for, realtime, applications, in, this, work, a, novel, heterogeneous, architecture, of, an, adaboost, detector, is, presented, this, architecture, achieves, higher, performance, while, consuming, fewer, hardware, resources, by, combining, an, integrated, arm, cortexa9, processor, with, a, dedicated, accelerator, this, architecture, can, be, configured, to, realize, various, objects, detection, by, simply, loading, different, parameters, 2d, parallelism, is, involved, in, accelerator, unit, combination, which, brings, more, flexibility, this, scheme, is, implemented, on, xilinx, zc702, platform, the, experiment, result, shows, that, 40, qvga, frames, per, second, can, be, achieved, for, realtime, face, detection, the, accelerator, achieves, more, than, 13, times, improvement, over, the, opencv, implementation, on, a, standalone, cortexa9, wrt, execution, speed, meanwhile, the, accelerator, consumes, 40, less, fpga, hardware, resources, than, the, priorart, implementation]|[adaboost, algorithm, based, haarlike, features, achieves, high, accuracy, 95, object, detection, meanwhile, massive, computing, power, needed, implement, cascaded, classifiers, involved, adaboost, detection, solve, problem, several, dedicated, hardware, solutions, proposed, realtime, applications, work, novel, heterogeneous, architecture, adaboost, detector, presented, architecture, achieves, higher, performance, consuming, fewer, hardware, resources, combining, integrated, arm, cortexa9, processor, dedicated, accelerator, architecture, configured, realize, various, objects, detection, simply, loading, different, parameters, 2d, parallelism, involved, accelerator, unit, combination, brings, flexibility, scheme, implemented, xilinx, zc702, platform, experiment, result, shows, 40, qvga, frames, per, second, achieved, realtime, face, detection, accelerator, achieves, 13, times, improvement, opencv, implementation, standalone, cortexa9, wrt, execution, speed, meanwhile, accelerator, consumes, 40, less, fpga, hardware, resources, priorart, implementation]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace, split\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Custom stop words\n",
    "custom_stop_words = ['doi', 'preprint', 'copyright', 'peer', 'reviewed', 'org', 'https', 'et', 'al', \n",
    "                     'author', 'figure', 'rights', 'reserved', 'permission', 'used', 'using', \n",
    "                     'biorxiv', 'medrxiv', 'license', 'fig', 'fig.', 'al.', 'Elsevier', 'PMC', \n",
    "                     'CZI', 'www']\n",
    "\n",
    "# Lowercase and remove punctuation\n",
    "df_cleaned = df.withColumn(\"cleaned_abstract\", lower(col(\"abstract\")))\n",
    "df_cleaned = df_cleaned.withColumn(\"cleaned_abstract\", regexp_replace(col(\"cleaned_abstract\"), r'[!()\\-\\[\\]{};:\\'\",<>./?@#$%^&*_~]', ''))\n",
    "\n",
    "# Tokenize the text\n",
    "df_tokenized = df_cleaned.withColumn(\"tokenized_abstract\", split(col(\"cleaned_abstract\"), \" \"))\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"tokenized_abstract\", outputCol=\"filtered_abstract\", \n",
    "                           stopWords=StopWordsRemover().getStopWords() + custom_stop_words)\n",
    "df_filtered = remover.transform(df_tokenized)\n",
    "\n",
    "# Show the cleaned dataframe\n",
    "df_filtered.select(\"abstract\", \"cleaned_abstract\", \"tokenized_abstract\", \"filtered_abstract\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1b69ecc-3166-43a8-832f-9e458fee8cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                  id|               title|            features|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|4aa69add-3978-480...|Dynamic analysis ...|(20000,[28,42,274...|\n",
      "|4ab3735c-80f1-472...|A new approach of...|(20000,[78,274,46...|\n",
      "|00127ee2-cb05-48c...|Preliminary Desig...|(20000,[1072,1241...|\n",
      "|001eef4f-1d00-4ae...|A Heterogeneous S...|(20000,[193,274,2...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "# Apply TF\n",
    "hashingTF = HashingTF(inputCol=\"filtered_abstract\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "df_featurized = hashingTF.transform(df_filtered)\n",
    "\n",
    "# Apply IDF\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idf_model = idf.fit(df_featurized)\n",
    "df_vectorized = idf_model.transform(df_featurized)\n",
    "\n",
    "# Select only the columns we need\n",
    "df_vectorized = df_vectorized.select(\"id\", \"title\", \"features\")\n",
    "df_vectorized.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b93221f3-b417-4570-8f82-af84f77f45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"PCA_KMeans\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38ef407b-5705-460d-8c9e-5b8d229445ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled DataFrame is empty. Unable to perform PCA.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if the sampled DataFrame is empty\n",
    "if df_sampled.isEmpty():\n",
    "    print(\"Sampled DataFrame is empty. Unable to perform PCA.\")\n",
    "else:\n",
    "    # Apply PCA to reduce dimensions (for example, to 20 components)\n",
    "    pca = PCA(k=20, inputCol=\"features\", outputCol=\"pca_features\")\n",
    "    pca_model = pca.fit(df_sampled)\n",
    "    df_pca = pca_model.transform(df_sampled)\n",
    "\n",
    "    # Determine the optimal number of clusters using the elbow method\n",
    "    costs = []\n",
    "    for k in range(2, 21):\n",
    "        kmeans = KMeans(k=k, seed=1, featuresCol=\"pca_features\")\n",
    "        model = kmeans.fit(df_pca)\n",
    "        cost = model.summary.trainingCost\n",
    "        costs.append(cost)\n",
    "\n",
    "    # Plot the elbow curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(2, 21), costs, marker='o')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a2cf472-8e74-4720-b7b5-8de8469a4f1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the K-means model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeans(k\u001b[38;5;241m=\u001b[39moptimal_k, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpca_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m kmeans\u001b[38;5;241m.\u001b[39mfit(\u001b[43mdf_pca\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m      9\u001b[0m df_clusters \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtransform(df_pca)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_pca' is not defined"
     ]
    }
   ],
   "source": [
    "# Assume the optimal number of clusters is determined to be 10\n",
    "optimal_k = 10\n",
    "\n",
    "# Train the K-means model\n",
    "kmeans = KMeans(k=optimal_k, seed=1, featuresCol=\"pca_features\")\n",
    "model = kmeans.fit(df_pca)\n",
    "\n",
    "# Make predictions\n",
    "df_clusters = model.transform(df_pca)\n",
    "df_clusters.select(\"id\", \"title\", \"prediction\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b48b7d-7a1f-4606-82e4-d9197f6ce766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return float(dot_product / (norm_v1 * norm_v2))\n",
    "\n",
    "cosine_similarity_udf = udf(cosine_similarity, DoubleType())\n",
    "\n",
    "# Build search engine function\n",
    "def recommend_papers(title, top_n=5):\n",
    "    # Find the cluster of the given paper title\n",
    "    paper_cluster = df_clusters.filter(df_clusters.title == title).select(\"prediction\").collect()[0][0]\n",
    "    \n",
    "    # Get all papers in the same cluster\n",
    "    cluster_papers = df_clusters.filter(df_clusters.prediction == paper_cluster)\n",
    "    \n",
    "    # Get the features of the given paper\n",
    "    paper_features = df_clusters.filter(df_clusters.title == title).select(\"features\").collect()[0][0]\n",
    "    \n",
    "    # Calculate cosine similarity and recommend top N papers\n",
    "    cluster_papers = cluster_papers.withColumn(\"similarity\", cosine_similarity_udf(cluster_papers.features, Vectors.dense(paper_features.toArray())))\n",
    "    recommendations = cluster_papers.orderBy(\"similarity\", ascending=False).limit(top_n)\n",
    "    \n",
    "    return recommendations.select(\"title\", \"similarity\").collect()\n",
    "\n",
    "# Example usage\n",
    "recommended_papers = recommend_papers(\"A new approach of....\", top_n=5)\n",
    "for rec in recommended_papers:\n",
    "    print(f\"Title: {rec['title']}, Similarity: {rec['similarity']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99023126-5311-4ece-979d-e092dea10bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327d7afc-6ba6-4893-b80e-93a33f9b35e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e6709-c183-4dc9-b516-dc1806b21fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ad630-d870-46bb-ad4d-aadbfd92543c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df1318-48df-4ea4-8626-cf22d7813da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02b036-17ed-44e9-b92a-ce767caabab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
